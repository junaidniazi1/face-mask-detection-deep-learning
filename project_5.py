# -*- coding: utf-8 -*-
"""PROJECT 5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UGT7Le2UbRQX9E1gHA0qp0l2kIETciyG
"""

!pip install kaggle

"""# importing the dataset"""

# -----------------------------------------------------------
# ‚úÖ Step 1: Create a hidden directory named ".kaggle"
#    inside your home directory (~).
#    This folder stores your Kaggle API key securely.
# -----------------------------------------------------------
!mkdir -p ~/.kaggle

# -----------------------------------------------------------
# ‚úÖ Step 2: Copy the "kaggle.json" file (your Kaggle API key)
#    into the newly created ~/.kaggle directory.
#    Make sure kaggle.json is in your current working directory before running this.
# -----------------------------------------------------------
!cp kaggle.json ~/.kaggle/

# -----------------------------------------------------------
# ‚úÖ Step 3: Change file permissions for kaggle.json.
#    This ensures only you (the current user) can read and write it.
#    Kaggle API requires this secure permission level (600).
# -----------------------------------------------------------
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d omkargurav/face-mask-dataset

# -----------------------------------------------------------
# ‚úÖ Step 1: Import the ZipFile class from the zipfile module.
#    This module is part of Python‚Äôs standard library and
#    allows you to work with ZIP archive files (extract, create, etc.).
# -----------------------------------------------------------
from zipfile import ZipFile

# -----------------------------------------------------------
# ‚úÖ Step 2: Specify the ZIP file name you want to extract.
#    Make sure "face-mask-dataset.zip" exists in your working directory.
# -----------------------------------------------------------
dataset = "face-mask-dataset.zip"

# -----------------------------------------------------------
# ‚úÖ Step 3: Open the ZIP file in read ('r') mode using a context manager.
#    This ensures the file is automatically closed after extraction.
# -----------------------------------------------------------
with ZipFile(dataset, 'r') as zip:

    # ‚úÖ Step 4: Extract all files from the ZIP archive
    #    into the current working directory.
    zip.extractall()

    # ‚úÖ Step 5: Print a confirmation message when extraction is complete.
    print('‚úÖ Extraction complete! All files have been unpacked successfully.')

!ls

"""# importing the dependecies"""

# -----------------------------------------------------------
# ‚úÖ Step 1: Import essential Python libraries
# -----------------------------------------------------------

# üìÅ 'os' is used for interacting with the operating system.
#     Helps in navigating directories, reading file paths, etc.
import os

# üî¢ 'numpy' is used for numerical operations and array manipulation.
#     It‚Äôs essential for handling image data as numerical arrays.
import numpy as np

# üé® 'matplotlib.pyplot' is used for visualizing data.
#     Commonly used to plot graphs or show images.
import matplotlib.pyplot as plt

# üñºÔ∏è 'matplotlib.image' (mpimg) helps in reading and displaying image files.
#     You can load images directly as arrays using mpimg.imread().
import matplotlib.image as mpimg

# üì∑ 'cv2' (OpenCV) is a powerful library for image processing.
#     You can resize, crop, apply filters, convert color formats, etc.
import cv2

# üé≤ 'random' is used for generating random numbers or selecting random samples.
#     Useful for data augmentation or visualizing random dataset samples.
import random

# üíæ 'pickle' is used for saving and loading Python objects in binary format.
#     Often used to store preprocessed data, trained models, or label encoders.
import pickle

# üëÅÔ∏è 'google.colab.patches' provides a function (cv2_imshow)
#     to display OpenCV images properly inside Google Colab notebooks.
#     (Normal cv2.imshow() doesn‚Äôt work in Colab.)
from google.colab.patches import cv2_imshow
from sklearn.model_selection import train_test_split

# -----------------------------------------------------------
# ‚úÖ Step 1: List all image files inside the folder 'with_mask'
# -----------------------------------------------------------

# 'os.listdir()' returns a list of all files and folders inside a given directory.
# Here, we are listing all images stored in the "with_mask" subfolder.
# Make sure the path '/content/data/with_mask' exists (this is typical in Google Colab).
with_mask_files = os.listdir('/content/data/with_mask')

# -----------------------------------------------------------
# ‚úÖ Step 2: Print the first 5 file names in the list
# -----------------------------------------------------------

# This helps you verify that the directory contains the expected image files.
print(with_mask_files[0:5])  # Display the first 5 image file names

# -----------------------------------------------------------
# ‚úÖ Step 3: Print the last 5 file names in the list
# -----------------------------------------------------------

# This ensures you‚Äôre seeing both the start and end of the dataset list,
# confirming that files have been read correctly.
print(with_mask_files[-5:])  # Display the last 5 image file names

without_mask_files=os.listdir('/content/data/without_mask')
print(without_mask_files[0:5])
print(without_mask_files[-5:])

# -----------------------------------------------------------
# ‚úÖ Count how many image files are in the 'with_mask' folder
# -----------------------------------------------------------

# len() returns the total number of elements in a list.
# Since 'with_mask_files' contains all filenames, we can use len() to count them.
num_with_mask = len(with_mask_files)
num_without_mask = len(without_mask_files)
# -----------------------------------------------------------
# ‚úÖ Print the result
# -----------------------------------------------------------
print(f"Total number of images in 'with_mask' folder: {num_with_mask}")
print(f"Total number of images in 'without_mask' folder: {num_without_mask}")

"""#LABELING THE DATAA"""

# -----------------------------------------------------------
# ‚úÖ Step 1: Create labels for each image category manually
# -----------------------------------------------------------

# For "with_mask" images:
# There are 3,725 images ‚Äî each should have the label 1
with_mask_label = [1] * 3725   # creates [1, 1, 1, ..., 1] (3725 times)

# For "without_mask" images:
# There are 3,828 images ‚Äî each should have the label 0
without_mask_label = [0] * 3828  # creates [0, 0, 0, ..., 0] (3828 times)

# -----------------------------------------------------------
# ‚úÖ Step 2: Verify the label lengths
# -----------------------------------------------------------
print("Number of 'with_mask' labels:", len(with_mask_label))
print("Number of 'without_mask' labels:", len(without_mask_label))

print(with_mask_label[0:5])
print(without_mask_label[0:5])
print(len(with_mask_label))
print(len(without_mask_label))

# -----------------------------------------------------------
# ‚úÖ Step 1: Combine labels of both classes into one list
# -----------------------------------------------------------

# '+' operator concatenates the two label lists.
# First part: all 1s for "with_mask"
# Second part: all 0s for "without_mask"
labels = with_mask_label + without_mask_label

# -----------------------------------------------------------
# ‚úÖ Step 2: Check the total number of labels
# -----------------------------------------------------------

# len(labels) gives the total number of images (both classes combined)
print("Total number of labels:", len(labels))

# -----------------------------------------------------------
# ‚úÖ Step 3: Preview some labels from the start and end
# -----------------------------------------------------------

# First 5 labels ‚Üí should be [1, 1, 1, 1, 1] (from 'with_mask')
print("First 5 labels:", labels[0:5])

# Last 5 labels ‚Üí should be [0, 0, 0, 0, 0] (from 'without_mask')
print("Last 5 labels:", labels[-5:])

"""# displying the with mask image"""

img=mpimg.imread('/content/data/with_mask/with_mask_100.jpg')
imgplot=plt.imshow(img)
plt.show

"""# image processing"""

# -----------------------------------------------------------
# üß† FACE MASK DETECTION ‚Äî DATA AUGMENTATION & PREPROCESSING
# -----------------------------------------------------------
# In this section, we will:
# 1. Load images from both 'with_mask' and 'without_mask' folders.
# 2. Resize each image to a fixed shape (100x100).
# 3. Apply data augmentation to make the model more robust.
# 4. Convert all processed images and labels into NumPy arrays.
# -----------------------------------------------------------

# -----------------------------------------------------------
# ‚úÖ Step 1: Import all necessary libraries
# -----------------------------------------------------------
import os                      # For handling file and folder paths
import cv2                     # OpenCV library for reading and processing images
import numpy as np              # For numerical operations and array handling
import random                   # For random operations (e.g., shuffling)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# ImageDataGenerator is used to perform data augmentation automatically.

# -----------------------------------------------------------
# ‚úÖ Step 2: Define the dataset paths (folders containing images)
# -----------------------------------------------------------
# The dataset contains two categories:
# - with_mask: people wearing masks
# - without_mask: people not wearing masks

with_mask_path = '/content/data/with_mask'        # Path to folder with mask images
without_mask_path = '/content/data/without_mask'  # Path to folder without mask images

# -----------------------------------------------------------
# ‚úÖ Step 3: Create empty lists to store image data and labels
# -----------------------------------------------------------
data = []     # Will hold all image arrays
labels = []   # Will hold corresponding class labels (1 for mask, 0 for no mask)

# -----------------------------------------------------------
# ‚úÖ Step 4: Initialize ImageDataGenerator for data augmentation
# -----------------------------------------------------------
# This generator will apply small random changes to the images (rotations, flips, zooms, etc.)
# It helps the model generalize better and not overfit.
datagen = ImageDataGenerator(
    rotation_range=20,        # Randomly rotate the image up to 20 degrees
    width_shift_range=0.1,    # Shift the image horizontally by up to 10%
    height_shift_range=0.1,   # Shift the image vertically by up to 10%
    shear_range=0.1,          # Apply shear transformation
    zoom_range=0.1,           # Zoom into the image randomly up to 10%
    horizontal_flip=True,     # Flip image horizontally (mirror)
    fill_mode='nearest'       # Fill empty pixels created during transformations
)

# -----------------------------------------------------------
# ‚úÖ Step 5: Define a helper function to load and preprocess images
# -----------------------------------------------------------
def load_and_preprocess_images(folder_path, label):
    """
    Loads images from the given folder, resizes them, augments them,
    and appends them to global data and labels lists.

    Parameters:
    folder_path (str): Path to the folder containing images
    label (int): Numeric label (1 = with mask, 0 = without mask)
    """
    # Loop through all files (images) in the folder
    for file in os.listdir(folder_path):
        try:
            # Get the full image path
            img_path = os.path.join(folder_path, file)

            # Read the image using OpenCV
            img = cv2.imread(img_path)

            # Proceed only if the image is successfully read
            if img is not None:
                # Resize image to a fixed size (100x100 pixels)
                img = cv2.resize(img, (100, 100))

                # Convert image color from BGR (default OpenCV format) to RGB
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # Add the original image to data list
                data.append(img)

                # Add corresponding label to labels list
                labels.append(label)

                # -----------------------------------------------------------
                # üåÄ Data Augmentation (Create 1 additional augmented image)
                # -----------------------------------------------------------
                # Expand dimensions to match generator input shape (1, 100, 100, 3)
                img_expanded = np.expand_dims(img, axis=0)

                # Generate one augmented image using datagen
                for batch in datagen.flow(img_expanded, batch_size=1):
                    # Add the augmented image to data list
                    data.append(batch[0].astype('uint8'))
                    # Add the same label for augmented image
                    labels.append(label)
                    break  # Only generate one new image per original image
        except Exception as e:
            # If any error occurs (like unreadable image), print it and skip that file
            print(f"Error loading image {file}: {e}")

# -----------------------------------------------------------
# ‚úÖ Step 6: Load images for both categories
# -----------------------------------------------------------
print("Loading 'with_mask' images...")
load_and_preprocess_images(with_mask_path, 1)   # Label = 1 for with_mask

print("Loading 'without_mask' images...")
load_and_preprocess_images(without_mask_path, 0) # Label = 0 for without_mask

# -----------------------------------------------------------
# ‚úÖ Step 7: Convert lists into NumPy arrays for ML model input
# -----------------------------------------------------------
# Convert data and labels to NumPy format (used in TensorFlow/Keras)
X = np.array(data)   # Image data array
y = np.array(labels) # Corresponding labels

# -----------------------------------------------------------
# ‚úÖ Step 8: Display dataset information
# -----------------------------------------------------------
print("‚úÖ Data augmentation and preprocessing complete!")
print("Total number of images:", X.shape[0])   # Total count of all (original + augmented) images
print("Image shape:", X.shape[1:])             # Each image's dimensions (height, width, channels)
print("Labels shape:", y.shape)                # Total count of labels (same as total images)

data[0].shape

type(X)

"""# train test split"""

# -----------------------------------------------------------
# ‚úÖ Step 8: Train-Test Split
# -----------------------------------------------------------

from sklearn.model_selection import train_test_split

# Split data first (before normalization)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

# -----------------------------------------------------------
# ‚úÖ Step 9: Normalize both training and testing data
# -----------------------------------------------------------

# Pixel values are between 0‚Äì255 ‚Üí scale to 0‚Äì1
X_train = X_train / 255.0
X_test = X_test / 255.0

# -----------------------------------------------------------
# ‚úÖ Step 10: Verify shapes and scaling
# -----------------------------------------------------------
print("‚úÖ Dataset successfully split and normalized!")
print("Training data shape:", X_train.shape)
print("Testing data shape:", X_test.shape)
print("Training labels shape:", y_train.shape)
print("Testing labels shape:", y_test.shape)

# Optional: Check min and max values to confirm normalization
print("Min pixel value:", X_train.min(), "| Max pixel value:", X_train.max())

data[0]

"""# building the neural network"""

# -----------------------------------------------------------
# ‚úÖ Step 11: Building the CNN Model
# -----------------------------------------------------------

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

# Initialize the CNN model
model = Sequential()

# -----------------------------------------------------------
# üîπ 1st Convolution Block
# -----------------------------------------------------------
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(BatchNormalization())          # Normalize activations
model.add(MaxPooling2D(pool_size=(2, 2))) # Reduce spatial size
model.add(Dropout(0.25))                 # Randomly drop 25% neurons to prevent overfitting

# -----------------------------------------------------------
# üîπ 2nd Convolution Block
# -----------------------------------------------------------
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# -----------------------------------------------------------
# üîπ 3rd Convolution Block
# -----------------------------------------------------------
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.3))

# -----------------------------------------------------------
# üîπ Flatten + Dense Layers (Fully Connected)
# -----------------------------------------------------------
model.add(Flatten())                    # Convert 2D ‚Üí 1D vector
model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.4))                 # Dropout for regularization

# -----------------------------------------------------------
# üîπ Output Layer
# -----------------------------------------------------------
model.add(Dense(1, activation='sigmoid'))  # Binary classification (mask / no mask)

# -----------------------------------------------------------

model.summary()

model.compile(
    optimizer='adam',                 # Adam optimizer (adaptive learning)
    loss='binary_crossentropy',       # Binary classification loss
    metrics=['accuracy']              # Track accuracy
)

# -----------------------------------------------------------
# ‚úÖ Step 13: Model Training with Early Stopping
# -----------------------------------------------------------
'''
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# -----------------------------------------------------------
# üîπ EarlyStopping Callback
# -----------------------------------------------------------
# Stops training when validation loss doesn't improve for 5 epochs
early_stop = EarlyStopping(
    monitor='val_loss',       # Watch validation loss
    patience=5,               # Stop if no improvement for 5 epochs
    restore_best_weights=True # Restore the best model
)

# -----------------------------------------------------------
# üîπ Train the model
# -----------------------------------------------------------
history = model.fit(
    X_train, y_train,
    validation_split=0.2,     # 20% of training data used for validation
    epochs=30,                # Maximum number of epochs
    batch_size=32,            # Number of images per training step
    callbacks=[early_stop],   # Add early stopping
    verbose=1                 # Show training progress
)

# -----------------------------------------------------------
# ‚úÖ Step 14: Evaluate on Test Data
# -----------------------------------------------------------
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)
print(f"‚úÖ Test Accuracy: {test_accuracy*100:.2f}%")
print(f"‚úÖ Test Loss: {test_loss:.4f}")

# -----------------------------------------------------------
# ‚úÖ Step 15: Plot Training Curves
# -----------------------------------------------------------

# Plot Accuracy
plt.figure(figsize=(8,4))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy During Training')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot Loss
plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss During Training')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
'''

# -----------------------------------------------------------
# ‚úÖ Step 13: Model Training (Without Early Stopping)
# -----------------------------------------------------------

import matplotlib.pyplot as plt

# -----------------------------------------------------------
# üîπ Train the model normally
# -----------------------------------------------------------
# We‚Äôll use 20 epochs; you can increase if accuracy keeps improving.
history = model.fit(
    X_train, y_train,
    validation_split=0.2,     # 20% of training data for validation
    epochs=40,                # Fixed number of epochs (no early stop)
    batch_size=32,            # Number of images processed per step
    verbose=1                 # Show training progress
)

# -----------------------------------------------------------
# ‚úÖ Step 14: Evaluate Model on Test Data
# -----------------------------------------------------------
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)
print(f"‚úÖ Test Accuracy: {test_accuracy*100:.2f}%")
print(f"‚úÖ Test Loss: {test_loss:.4f}")

# -----------------------------------------------------------
# ‚úÖ Step 15: Plot Training Accuracy & Loss
# -----------------------------------------------------------

# Plot Accuracy curve
plt.figure(figsize=(8, 4))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy During Training')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot Loss curve
plt.figure(figsize=(8, 4))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss During Training')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# -----------------------------------------------------------
# ‚úÖ Step 16: Evaluate the Model on Test Data
# -----------------------------------------------------------

# Evaluate model performance on unseen (test) data
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)

# Display results
print("‚úÖ Model Evaluation Results:")
print(f"Test Accuracy: {test_accuracy*100:.2f}%")
print(f"Test Loss: {test_loss:.4f}")

# -----------------------------------------------------------
# ‚úÖ Step 17: Save the Model for Future Use
# -----------------------------------------------------------

# Save the trained model in HDF5 format (.h5)
model.save("face_mask_detector.h5")

print("üíæ Model saved successfully as 'face_mask_detector.h5'")

# -----------------------------------------------------------
# ‚úÖ Step 18: Optional ‚Äî Reload Model to Confirm It Works
# -----------------------------------------------------------

from tensorflow.keras.models import load_model

# Load the saved model
loaded_model = load_model("face_mask_detector.h5")

# Evaluate again (to verify the loaded model works correctly)
loss, acc = loaded_model.evaluate(X_test, y_test, verbose=0)
print(f"üîÅ Reloaded Model Accuracy: {acc*100:.2f}%")

# -----------------------------------------------------------
# ‚úÖ Step 19: Predict on Custom User Image
# -----------------------------------------------------------

from tensorflow.keras.models import load_model
from google.colab import files
import cv2
import numpy as np
import matplotlib.pyplot as plt

# -----------------------------------------------------------
# üîπ 1. Load your trained model
# -----------------------------------------------------------
model = load_model("face_mask_detector.h5")
print("‚úÖ Model loaded successfully!")

# -----------------------------------------------------------
# üîπ 2. Let user upload an image
# -----------------------------------------------------------
uploaded = files.upload()  # Opens a file picker for the user

for file_name in uploaded.keys():
    print(f"\nüìÇ Uploaded file: {file_name}")

    # -----------------------------------------------------------
    # üîπ 3. Read and preprocess the uploaded image
    # -----------------------------------------------------------
    img_path = file_name
    img = cv2.imread(img_path)

    # Check if image loaded correctly
    if img is None:
        print("‚ùå Error: Could not load image.")
        continue

    # Resize to same size as training images
    img = cv2.resize(img, (100, 100))

    # Convert BGR ‚Üí RGB (since OpenCV loads in BGR format)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Normalize pixel values (0‚Äì1 range)
    img_normalized = img_rgb / 255.0

    # Expand dimensions ‚Üí model expects (1, 100, 100, 3)
    img_input = np.expand_dims(img_normalized, axis=0)

    # -----------------------------------------------------------
    # üîπ 4. Make prediction
    # -----------------------------------------------------------
    prediction = model.predict(img_input)[0][0]  # single output value between 0‚Äì1

    # -----------------------------------------------------------
    # üîπ 5. Interpret result
    # -----------------------------------------------------------
    if prediction >= 0.5:
        label = "üò∑ With Mask"
        color = (0, 255, 0)  # green
    else:
        label = "‚ùå Without Mask"
        color = (255, 0, 0)  # red

    # -----------------------------------------------------------
    # üîπ 6. Display image with prediction
    # -----------------------------------------------------------
    plt.imshow(img_rgb)
    plt.title(f"Prediction: {label}")
    plt.axis('off')
    plt.show()

    print(f"‚úÖ Prediction Result: {label} (Confidence: {prediction:.2f})")

# ‚úÖ Save model in new Keras format
model.save('face_mask_detector.keras')

print("üíæ Model saved successfully as 'face_mask_detector.keras'")

# ‚úÖ Load the saved model
from tensorflow.keras.models import load_model
loaded_model = load_model('face_mask_detector.keras')

# Evaluate again to confirm it's working
loss, acc = loaded_model.evaluate(X_test, y_test)
print(f"üîÅ Reloaded Model Accuracy: {acc * 100:.2f}%")
print(f"Reloaded Model Loss: {loss:.4f}")

